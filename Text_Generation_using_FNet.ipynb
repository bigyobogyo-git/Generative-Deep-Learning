{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba2b1acc-8861-44e4-8571-6371107304aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:16:09.056707: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-13 15:16:09.056729: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-13 15:16:09.057732: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-13 15:16:09.062767: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-13 15:16:09.554957: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "\n",
    "# Defining hyperparameters\n",
    "\n",
    "VOCAB_SIZE = 8192\n",
    "MAX_SAMPLES = 50000\n",
    "BUFFER_SIZE = 20000\n",
    "MAX_LENGTH = 40\n",
    "EMBED_DIM = 256\n",
    "LATENT_DIM = 512\n",
    "NUM_HEADS = 8\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a931720e-12b8-4f93-bb59-957a9388e28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:18:18.316138: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.646435: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.650904: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.653377: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.654983: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.656573: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.810603: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.811531: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.812341: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-11-13 15:18:18.813114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8981 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "path_to_zip = keras.utils.get_file(\n",
    "    \"cornell_movie_dialogs.zip\",\n",
    "    origin=\"http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "path_to_dataset = os.path.join(\n",
    "    os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\"\n",
    ")\n",
    "path_to_movie_lines = os.path.join(path_to_dataset, \"movie_lines.txt\")\n",
    "path_to_movie_conversations = os.path.join(path_to_dataset, \"movie_conversations.txt\")\n",
    "\n",
    "\n",
    "def load_conversations():\n",
    "    # Helper function for loading the conversation splits\n",
    "    id2line = {}\n",
    "    with open(path_to_movie_lines, errors=\"ignore\") as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
    "        id2line[parts[0]] = parts[4]\n",
    "\n",
    "    inputs, outputs = [], []\n",
    "    with open(path_to_movie_conversations, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    for line in lines:\n",
    "        parts = line.replace(\"\\n\", \"\").split(\" +++$+++ \")\n",
    "        # get conversation in a list of line ID\n",
    "        conversation = [line[1:-1] for line in parts[3][1:-1].split(\", \")]\n",
    "        for i in range(len(conversation) - 1):\n",
    "            inputs.append(id2line[conversation[i]])\n",
    "            outputs.append(id2line[conversation[i + 1]])\n",
    "            if len(inputs) >= MAX_SAMPLES:\n",
    "                return inputs, outputs\n",
    "    return inputs, outputs\n",
    "\n",
    "\n",
    "questions, answers = load_conversations()\n",
    "\n",
    "# Splitting training and validation sets\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((questions[:40000], answers[:40000]))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((questions[40000:], answers[40000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de9bcbe6-054b-45af-a7cd-7909d7abcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sentence):\n",
    "    sentence = tf.strings.lower(sentence)\n",
    "    # Adding a space between the punctuation and the last word to allow better tokenization\n",
    "    sentence = tf.strings.regex_replace(sentence, r\"([?.!,])\", r\" \\1 \")\n",
    "    # Replacing multiple continuous spaces with a single space\n",
    "    sentence = tf.strings.regex_replace(sentence, r\"\\s\\s+\", \" \")\n",
    "    # Replacing non english words with spaces\n",
    "    sentence = tf.strings.regex_replace(sentence, r\"[^a-z?.!,]+\", \" \")\n",
    "    sentence = tf.strings.strip(sentence)\n",
    "    sentence = tf.strings.join([\"[start]\", sentence, \"[end]\"], separator=\" \")\n",
    "    return sentence\n",
    "\n",
    "\n",
    "vectorizer = layers.TextVectorization(\n",
    "    VOCAB_SIZE,\n",
    "    standardize=preprocess_text,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_LENGTH,\n",
    ")\n",
    "\n",
    "# We will adapt the vectorizer to both the questions and answers\n",
    "# This dataset is batched to parallelize and speed up the process\n",
    "vectorizer.adapt(tf.data.Dataset.from_tensor_slices((questions + answers)).batch(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d8f2f3-73d7-4bfb-a467-643b462b29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(inputs, outputs):\n",
    "    inputs, outputs = vectorizer(inputs), vectorizer(outputs)\n",
    "    # One extra padding token to the right to match the output shape\n",
    "    outputs = tf.pad(outputs, [[0, 1]])\n",
    "    return (\n",
    "        {\"encoder_inputs\": inputs, \"decoder_inputs\": outputs[:-1]},\n",
    "        {\"outputs\": outputs[1:]},\n",
    "    )\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.map(vectorize_text, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = (\n",
    "    train_dataset.cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "val_dataset = val_dataset.cache().batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97e99ff2-7847-46b6-b036-a432a236269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNetEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Casting the inputs to complex64\n",
    "        inp_complex = tf.cast(inputs, tf.complex64)\n",
    "        # Projecting the inputs to the frequency domain using FFT2D and\n",
    "        # extracting the real part of the output\n",
    "        fft = tf.math.real(tf.signal.fft2d(inp_complex))\n",
    "        proj_input = self.layernorm_1(inputs + fft)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af130059-1b0e-4ae2-91d2-491429c8823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class FNetDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    encoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
    "    x = PositionalEmbedding(MAX_LENGTH, VOCAB_SIZE, EMBED_DIM)(encoder_inputs)\n",
    "    encoder_outputs = FNetEncoder(EMBED_DIM, LATENT_DIM)(x)\n",
    "    encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "    decoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
    "    encoded_seq_inputs = keras.Input(\n",
    "        shape=(None, EMBED_DIM), name=\"decoder_state_inputs\"\n",
    "    )\n",
    "    x = PositionalEmbedding(MAX_LENGTH, VOCAB_SIZE, EMBED_DIM)(decoder_inputs)\n",
    "    x = FNetDecoder(EMBED_DIM, LATENT_DIM, NUM_HEADS)(x, encoded_seq_inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    decoder_outputs = layers.Dense(VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "    decoder = keras.Model(\n",
    "        [decoder_inputs, encoded_seq_inputs], decoder_outputs, name=\"outputs\"\n",
    "    )\n",
    "    decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "    fnet = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"fnet\")\n",
    "    return fnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b101270-a155-42a4-a0e9-c0e7ea781619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnet = create_model()\n",
    "fnet.compile(\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99365a34-463c-4ce3-abe9-0ccf106a801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:18:23.294047: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2025-11-13 15:18:23.756013: I external/local_xla/xla/service/service.cc:168] XLA service 0x7793020ca9d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-13 15:18:23.756029: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2025-11-13 15:18:23.760318: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763043503.816583   10393 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 42s 60ms/step - loss: 4.3974 - accuracy: 0.2820 - val_loss: 3.9751 - val_accuracy: 0.3165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7793f6470040>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnet.fit(train_dataset, epochs=1, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfd2bc67-a855-4bb9-897c-a26a7036bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 224ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'i m not . '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB = vectorizer.get_vocabulary()\n",
    "\n",
    "\n",
    "def decode_sentence(input_sentence):\n",
    "    # Mapping the input sentence to tokens and adding start and end tokens\n",
    "    tokenized_input_sentence = vectorizer(\n",
    "        tf.constant(\"[start] \" + preprocess_text(input_sentence) + \" [end]\")\n",
    "    )\n",
    "    # Initializing the initial sentence consisting of only the start token.\n",
    "    tokenized_target_sentence = tf.expand_dims(VOCAB.index(\"[start]\"), 0)\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # Get the predictions\n",
    "        predictions = fnet.predict(\n",
    "            {\n",
    "                \"encoder_inputs\": tf.expand_dims(tokenized_input_sentence, 0),\n",
    "                \"decoder_inputs\": tf.expand_dims(\n",
    "                    tf.pad(\n",
    "                        tokenized_target_sentence,\n",
    "                        [[0, MAX_LENGTH - tf.shape(tokenized_target_sentence)[0]]],\n",
    "                    ),\n",
    "                    0,\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "        # Calculating the token with maximum probability and getting the corresponding word\n",
    "        sampled_token_index = tf.argmax(predictions[0, i, :])\n",
    "        sampled_token = VOCAB[sampled_token_index.numpy()]\n",
    "        # If sampled token is the end token then stop generating and return the sentence\n",
    "        if tf.equal(sampled_token_index, VOCAB.index(\"[end]\")):\n",
    "            break\n",
    "        decoded_sentence += sampled_token + \" \"\n",
    "        tokenized_target_sentence = tf.concat(\n",
    "            [tokenized_target_sentence, [sampled_token_index]], 0\n",
    "        )\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "decode_sentence(\"Where have you been all this time?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1576f00-8364-4d7e-8266-6c64580e1f9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02af15ad-e2cc-4697-82ff-e6b0b225452e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8db5a-bc56-43b7-ae2d-b8cf6f81aede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3c0d05-9aa9-4314-a8f5-ffb9c54f68f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971d0b6-035b-44dd-9640-b443fe85fa43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2d10a6-863a-4c30-a513-218154656e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d39fe-5fae-4e8a-981a-deef791bf203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d11d0-b54c-4afe-85d4-d8c7ae1e0299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bff890-1150-481f-b1c6-55d565d050a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4942e267-2cb7-4c9e-bdfa-5d7d37ba2d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656370d-e031-4b8a-981c-ef149a0b03cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966b247-55b0-4adb-a991-8db30c447980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598ab96-4e96-4e9a-8d21-a32585112d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c60b5b0-aecd-4342-baf2-e1715e8a1c91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1418068-58e8-4525-ab77-233d295f4caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10016976-ce97-4623-a3f2-b5e0c7a8ae03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a1808a-c143-4648-96d3-7ff940684a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282a73b6-821e-4246-ab42-90ccd206c56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e89032-d3fa-4f19-99e0-ad28249beb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35f834-7363-4642-8c6e-97b77e4750a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e371064c-7178-4144-bb8f-ba5b2b30cec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb07991-e786-49a6-baed-b3b51205c1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95849917-620a-4bd4-9ee0-85cd06c89177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556df0b1-59e5-4bc2-9c13-dbe5ec2e41fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0fa058-e87f-478b-ba35-4bcde06c7a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc18fa85-dbf7-406a-9753-4f0417f5d733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22af1f-6407-45bb-82b7-2f76332ca011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a4b71-6f27-4877-a2bb-fbe83e7762b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f7681-c884-4398-ab40-81ec62b88407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba8f06-5356-43fc-a8f0-741f128f9bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f474c-5705-4bfa-94e7-c93ec8880a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
